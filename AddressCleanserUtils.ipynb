{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:47:08.249369Z",
     "start_time": "2021-05-12T13:47:08.233198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-e54528aa040b>:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import  tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jellyfish'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e54528aa040b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjellyfish\u001b[0m\u001b[0;31m#88942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jellyfish'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm.autonotebook import  tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "import jellyfish#88942\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.multiprocessing import get\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s]  %(message)s', stream=sys.stdout)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.289408Z",
     "start_time": "2020-05-04T07:48:35.282319Z"
    }
   },
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to python AddressCleanserUtils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.304087Z",
     "start_time": "2020-05-04T07:48:35.297269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "within_jupyter=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.328776Z",
     "start_time": "2020-05-04T07:48:35.309569Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def log(arg):\n",
    "    if (type(arg) == pd.core.frame.DataFrame) or (type(arg) == pd.core.frame.Series):\n",
    "        log_display(arg)\n",
    "    else:\n",
    "        logging.info(arg)\n",
    "\n",
    "def vlog(arg):\n",
    "    if (type(arg) == pd.core.frame.DataFrame) or (type(arg) == pd.core.frame.Series):\n",
    "        vlog_display(arg)\n",
    "    else:\n",
    "        logging.debug(arg)\n",
    "\n",
    "        \n",
    "def log_display(df):\n",
    "    if within_jupyter: \n",
    "        if logger.getEffectiveLevel() <= logging.INFO:\n",
    "            display(df)\n",
    "    else: \n",
    "        with pd.option_context(\"display.max_columns\", None, 'display.width', 200):\n",
    "            log(\"\\n\"+str(df))\n",
    "        \n",
    "def vlog_display(df):\n",
    "    if within_jupyter: \n",
    "        if logger.getEffectiveLevel() <= logging.DEBUG:\n",
    "            display(df)\n",
    "    else: \n",
    "        with pd.option_context(\"display.max_columns\", None,  'display.width', 200):\n",
    "            vlog(\"\\n\"+str(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.340843Z",
     "start_time": "2020-05-04T07:48:35.334009Z"
    }
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar(dt=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.359022Z",
     "start_time": "2020-05-04T07:48:35.348530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mapping of nominatim results fields on our output fields\n",
    "collapse_params = {\n",
    "    \"addr_out_street\":   [\"road\", \"pedestrian\",\"footway\", \"cycleway\", \"path\", \"address27\", \"construction\", \"hamlet\", \"park\"],\n",
    "    \"addr_out_city\"  :   [\"town\", \"village\", \"city_district\", \"county\", \"city\"],\n",
    "    \"addr_out_number\":   [\"house_number\"],\n",
    "    \"addr_out_country\":  [\"country\"],\n",
    "    \"addr_out_postcode\": [\"postcode\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.370237Z",
     "start_time": "2020-05-04T07:48:35.363858Z"
    }
   },
   "outputs": [],
   "source": [
    "osm_addr_field = \"osm_addr\" # name of the field of the address sent to Nominatim\n",
    "\n",
    "similarity_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.391215Z",
     "start_time": "2020-05-04T07:48:35.379591Z"
    }
   },
   "outputs": [],
   "source": [
    "timestats = {\"transformer\": timedelta(0),\n",
    "             \"osm\": timedelta(0),\n",
    "             \"osm_post\": timedelta(0),\n",
    "             \"checker\": timedelta(0),\n",
    "             \"photon\": timedelta(0),\n",
    "             \"libpostal\": timedelta(0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:16:06.603972Z",
     "start_time": "2019-09-02T12:16:06.596466Z"
    }
   },
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.408295Z",
     "start_time": "2020-05-04T07:48:35.397701Z"
    }
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "def remove_accents(input_str):\n",
    "    if pd.isnull(input_str):\n",
    "        return None\n",
    "    \n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.439155Z",
     "start_time": "2020-05-04T07:48:35.413096Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def house_number_compare(n1, n2):\n",
    "    \"\"\"\n",
    "    Compare two pd.Series of house numbers\n",
    "    - if n1 == n2 (and not empty) --> 1\n",
    "    - else we split n1 and n2 in chunks of numbers : \n",
    "        - if first chunk of n1 = second chunk of n2 -->  0.8  (e.g : 10 vs 10-12)\n",
    "        - else second chunk of n1 = first chunk of n2 --> 0.8 (e.g. 10-12 vs 12)\n",
    "    - else if only numbers are equal (and not empty) --> 0.5  (e.g., '10a' vs '10 B' vs '10')\n",
    "    \"\"\"\n",
    "    n1 = n1.fillna(\"\").astype(str).str.strip()\n",
    "    n2 = n2.fillna(\"\").astype(str).str.strip()\n",
    "    \n",
    "    res= ((n1==n2) & (n1.str.len()>0)).astype(float)\n",
    "    \n",
    "    n1_split = n1.str.split(\"[^0-9]\", expand=True)\n",
    "    n2_split = n2.str.split(\"[^0-9]\", expand=True)\n",
    "    \n",
    "    if n2_split.shape[1]>1:\n",
    "        res[(res == 0) & ((n1_split[0] == n2_split[1]) & (n2_split[1].str.len()>0))] = 0.8\n",
    "        \n",
    "    if n1_split.shape[1]>1:\n",
    "        res[(res == 0) & ((n1_split[1] == n2_split[0]) & (n1_split[1].str.len()>0))] = 0.8\n",
    "    \n",
    "    res[(res == 0) & (n1.str.replace(\"[^0-9]\", \"\") == n2.str.replace(\"[^0-9]\", \"\")) & ( n1.str.len()>0) & ( n2.str.len()>0)] = 0.5\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.464534Z",
     "start_time": "2020-05-04T07:48:35.445842Z"
    }
   },
   "outputs": [],
   "source": [
    "def postcode_compare(s1, s2):\n",
    "    \"\"\"Compare postcodes.\n",
    "\n",
    "    If the postcodes in both records are identical, the similarity\n",
    "    is 1. If the first two values agree and the last two don't, then\n",
    "    the similarity is 0.5. Otherwise, the similarity is 0.\n",
    "    \"\"\"\n",
    "    s1 = s1.fillna(\"\").astype(str).str.replace(\"^[A-Z]-?\", \"\")\n",
    "    s2 = s2.fillna(\"\").astype(str).str.replace(\"^[A-Z]-?\", \"\")\n",
    "    \n",
    "    # check if the postcode are identical (return 1 or 0)\n",
    "    sim = (s1 == s2).astype(float)\n",
    "    # one is missing\n",
    "    sim[(sim == 0) & ((s1.fillna(\"\").str.len()==0) | (s2.fillna(\"\").str.len()==0))] = 0.1\n",
    "    \n",
    "    # check the first 2 numbers of the distinct comparisons\n",
    "    \n",
    "    sim[(sim == 0) & (s1.str[0:2] == s2.str[0:2])] = 0.5\n",
    "    sim[(sim == 0) & (s1.str[0:1] == s2.str[0:1])] = 0.3\n",
    "\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.479771Z",
     "start_time": "2020-05-04T07:48:35.470881Z"
    }
   },
   "outputs": [],
   "source": [
    "def levenshtein_similarity(str1, str2):\n",
    "    return 1-jellyfish.damerau_levenshtein_distance(str1, str2)/max(len(str1), len(str2)) if (len(str1) > 0 or len(str2) > 0  ) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.497090Z",
     "start_time": "2020-05-04T07:48:35.485244Z"
    }
   },
   "outputs": [],
   "source": [
    "def inclusion_test(s1, s2):\n",
    "    \"\"\" \n",
    "    Check that a string s1 is equal to another string s2, except that s2 contains an additional substring\n",
    "    Example : \"Avenue C Berten\" vs \"Avenue Clovis Berten\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    import os\n",
    "    l_pref = len(os.path.commonprefix([s1, s2]))\n",
    "    l_suf =  len(os.path.commonprefix([s1[::-1], s2[::-1]]))\n",
    "\n",
    "    res = 1 if (l_pref>0)  and (l_suf > 0) and (l_pref+l_suf >= min(len(s1), len(s2))) else 0\n",
    "#     if res == 1:\n",
    "#         print(s1, s2, res)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.510117Z",
     "start_time": "2020-05-04T07:48:35.502683Z"
    }
   },
   "outputs": [],
   "source": [
    "# s1=\"NEU\"\n",
    "# s2 = \"NEUCHATEAU\"\n",
    "# import os\n",
    "# l_pref = len(os.path.commonprefix([s1, s2]))\n",
    "# l_suf =  len(os.path.commonprefix([s1[::-1], s2[::-1]]))\n",
    "# l_pref, l_suf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.529703Z",
     "start_time": "2020-05-04T07:48:35.517146Z"
    }
   },
   "outputs": [],
   "source": [
    "def fingerprint(column):\n",
    "    cleaned_column = column.fillna(\"\")\n",
    "#     cleaned_column = cleaned_column.str.upper().apply(remove_accents)\n",
    "    cleaned_column = cleaned_column.str.replace(\"[^A-Z]\", \" \")\n",
    "    cleaned_column = cleaned_column.str.strip()\n",
    "    cleaned_column = cleaned_column.str.split(\"[ ]+\")\n",
    "    \n",
    "    cleaned_column = cleaned_column.apply(lambda x: sorted(list(set(x))))\n",
    "    cleaned_column = cleaned_column.apply(\" \".join)\n",
    "    return cleaned_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.581627Z",
     "start_time": "2020-05-04T07:48:35.536237Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : replacement seulement si dans les 2 inputs en même temps  --> Pour éviter que \"Avenue Louise\" et \"Place Louise\" aient une similarité de 100%\n",
    "\n",
    "street_compare_removes = [r\"\\([A-Z.]+\\)\", \n",
    "                          # r\"[^A-Z ]+\",\n",
    "                          r\"\\b(AVENUE|RUE|CHAUSSEE|BOULEVARD|PLACE)\\b\",\n",
    "                          r\"(STRAAT|LAAN|STEENWEG|WEG)\\b\"\n",
    "                         ]\n",
    "\n",
    "dontwatchthis = \"DONOTCONSIDERTHISSTRING\"\n",
    "def _street_compare(street1, street2, compare_algo, street_compare_removes):\n",
    "    \n",
    "    streets = pd.DataFrame()\n",
    "    streets[\"STR1\"] = street1\n",
    "    streets[\"STR2\"] = street2\n",
    "    \n",
    "    for i in [\"STR1\", \"STR2\"]:\n",
    "        for scr in street_compare_removes:\n",
    "            streets[i] = streets[i].str.replace(scr, \"\")\n",
    "        \n",
    "        streets[i] = streets[i].str.strip().str.replace(\" [ ]+\", \" \")\n",
    "    \n",
    "    # if diff length > 10 : --> 0, othewise : 2\n",
    "    res = (streets.STR1.fillna(\"\").str.len() - streets.STR1.fillna(\"\").str.len() < 10).astype(float) *2\n",
    "    \n",
    "    # If one is equal to \"dontwatchthis\" : 0\n",
    "    res[(res == 2) & ((streets.STR1 == dontwatchthis) | (streets.STR2 == dontwatchthis)) ] = 0.0\n",
    "    \n",
    "    # if both is empty : 1\n",
    "    res[(res == 2) & (streets.STR1.fillna(\"\") == \"\") & (streets.STR2.fillna(\"\") == \"\") ] = 1.0\n",
    "    \n",
    "    # Otherwise (still == 2): compute distance\n",
    "    \n",
    "    \n",
    "    if (res == 2).any():\n",
    "        res[res == 2] = streets[res == 2].fillna(\"\").apply(lambda row : compare_algo(row.STR1, row.STR2), axis=1)\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def street_compare(street1, street2, compare_algo = levenshtein_similarity):\n",
    "\n",
    "    if street1.shape[0] == 0:\n",
    "        return pd.Series(index=street1.index)\n",
    "    \n",
    "    # For Brussels (or bilingual regions), we typically get \"Avenue Louise - Louizalaan\" for street\n",
    "    # We also often get (in input) streets like \"Bruxelles, Avenue Louise\", or \"Avenue Louise, 10\"\n",
    "    # Set \"dontwatchthis\" for values that do not split, but where a column appear because of other values being split\n",
    "    \n",
    "    street_split_a = street1.fillna(\"\").str.replace(\",\", \" - \").str.split(\" - \", expand=True).fillna(dontwatchthis)\n",
    "    street_split_b = street2.fillna(\"\").str.replace(\",\", \" - \").str.split(\" - \", expand=True).fillna(dontwatchthis)\n",
    "\n",
    "    #display(pd.concat([street1, street2], axis=1))\n",
    "    #display(pd.concat([street_split_a, street_split_b], axis=1))\n",
    "    \n",
    "    street_distances = pd.DataFrame()\n",
    "    for ai in range(street_split_a.shape[1]):\n",
    "        str_a = street_split_a[ai].str.upper().apply(remove_accents).str.replace( r\"[^A-Z ]+\", \" \").str.replace(\" [ ]+\", \" \").str.strip()\n",
    "\n",
    "        for bi in range(street_split_b.shape[1]):\n",
    "            str_b = street_split_b[bi].str.upper().apply(remove_accents).str.replace( r\"[^A-Z ]+\", \" \").str.replace(\" [ ]+\", \" \").str.strip()\n",
    "\n",
    "            street_distances[\"SIM_street_a{}b{}\".format(ai,bi)] =  _street_compare(str_a, str_b, compare_algo=compare_algo, street_compare_removes=street_compare_removes)\n",
    "            # to calculate (strict) inclusion, we do not remove \"street words\" (Rue, Avenue ...) \n",
    "            street_distances[\"INC_street_a{}b{}\".format(ai,bi)] =  _street_compare(str_a, str_b, compare_algo=inclusion_test, street_compare_removes=[])\n",
    "            \n",
    "            fgpta = fingerprint(str_a)\n",
    "            fgptb = fingerprint(str_b)\n",
    "            \n",
    "            street_distances[\"FING_street_a{}b{}\".format(ai,bi)] =  _street_compare(fgpta, fgptb, compare_algo=compare_algo, street_compare_removes=street_compare_removes)\n",
    "    \n",
    "    street_distances[\"SIM_street\"] =  street_distances[filter(lambda x: \"SIM_street_a\" in x \n",
    "                                                              or \"INC_street_a\" in x\n",
    "                                                              or \"FING_street_a\" in x, street_distances)].max(axis=1)    \n",
    "#     display(street_distances[street1.fillna(\"\").str.contains(\"AUTOSNELWEGEN\") ])\n",
    "    vlog(f\"Street compare: {street1.name}, {street2.name}\")\n",
    "    vlog(pd.concat([street_split_a, street_split_b, street_distances], axis=1))\n",
    "    return street_distances[\"SIM_street\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T09:01:04.816394Z",
     "start_time": "2020-04-03T09:01:04.771053Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.600376Z",
     "start_time": "2020-05-04T07:48:35.587491Z"
    }
   },
   "outputs": [],
   "source": [
    "def city_compare(city1, city2, compare_algo = levenshtein_similarity):\n",
    "    \n",
    "    cities = pd.DataFrame()\n",
    "    cities[\"CITY1\"] = city1\n",
    "    cities[\"CITY2\"] = city2\n",
    "    \n",
    "    for i in [\"CITY1\", \"CITY2\"]:\n",
    "        cities[i] = cities[i].str.upper().apply(remove_accents)\n",
    "        cities[i] = cities[i].str.strip().str.replace(\" [ ]+\", \" \")\n",
    "        \n",
    "    return cities.fillna(\"\").apply(lambda row : compare_algo(row.CITY1, row.CITY2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.641276Z",
     "start_time": "2020-05-04T07:48:35.606053Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def ignore_mismatch_keep_bests(addr_matches, addr_key_field, \n",
    "                               street_fields_a, housenbr_field_a, postcode_field_a, city_field_a, \n",
    "                               street_field_b, housenbr_field_b, postcode_field_b, city_field_b, #split_comma = True,\n",
    "                               similarity_threshold=similarity_threshold, max_res=1, secondary_sort_field = \"osm_order\"):\n",
    "    \n",
    "    if addr_matches.shape[0] == 0:\n",
    "        return addr_matches, addr_matches\n",
    "    \n",
    "    distances = pd.DataFrame(index=addr_matches.index)\n",
    "    \n",
    "    street_b = addr_matches[street_field_b]\n",
    "        \n",
    "    distances[\"SIM_street\"] = -1\n",
    "    \n",
    "    vlog(\"Will compare streets\")\n",
    "    for street_field_a in street_fields_a :\n",
    "        # Only compute a new street distance if the computed distance is below the threshold so far\n",
    "        x = (distances[\"SIM_street\"] < similarity_threshold)  \n",
    "        \n",
    "        distances.loc[x, \"SIM_street\"] =  street_compare(addr_matches[street_field_a][x].fillna(\"\"), street_b[x])\n",
    "        distances.loc[x, \"SIM_street_which\"] =  street_field_a # last field that have been compared\n",
    "    \n",
    "    wsu = \" ; \".join([f\"{r}: {c}\" for r, c in distances[distances[\"SIM_street\"] >= similarity_threshold][\"SIM_street_which\"].value_counts().iteritems()])\n",
    "    vlog(f\"Which street used: {wsu}\")\n",
    "\n",
    "    \n",
    "    w = distances[(distances[\"SIM_street\"] >= similarity_threshold)&(distances[\"SIM_street_which\"]!=street_fields_a[0] )].merge(addr_matches, left_index=True, right_index=True)\n",
    "    vlog(f\"Cases where street ({street_fields_a[0]}) wasn't used to validate results: \")\n",
    "    \n",
    "    vlog(w[np.concatenate([[addr_key_field], street_fields_a, [housenbr_field_a, postcode_field_a, city_field_a, \n",
    "                               street_field_b, housenbr_field_b, postcode_field_b, city_field_b]])])\n",
    "    \n",
    "    distances[\"SIM_house_nbr\"] = house_number_compare(addr_matches[housenbr_field_a].fillna(\"\"), addr_matches[housenbr_field_b].fillna(\"\"))\n",
    "    \n",
    "    distances[\"SIM_zip\"] =       postcode_compare(addr_matches[postcode_field_a].fillna(\"\"), addr_matches[postcode_field_b].fillna(\"\"))\n",
    "    \n",
    "    distances[\"SIM_city\"] =      city_compare(addr_matches[city_field_a].fillna(\"\"), addr_matches[city_field_b].fillna(\"\"))\n",
    "    \n",
    "    elimination_rule = ((distances.SIM_zip < 0.1) & (distances.SIM_city < similarity_threshold)) | \\\n",
    "                        ((distances.SIM_street < similarity_threshold)  )\n",
    "    \n",
    "    rejected = addr_matches[elimination_rule].merge(distances, left_index=True, right_index=True).copy()\n",
    "    \n",
    "    rejected[\"reject_reason\"] = \"mismatch\"\n",
    "\n",
    "    # Remove non acceptable results\n",
    "    \n",
    "    result = addr_matches[~elimination_rule].merge(distances, left_index=True, right_index=True).sort_values([addr_key_field, \"SIM_street\", \"SIM_house_nbr\", secondary_sort_field], ascending=[True, False, False, True])\n",
    "    \n",
    "    # Keep only the first ones\n",
    "    result_head = result.groupby([addr_key_field]).head(max_res)#.drop(\"level_2\", axis=1)#.set_index([key, addr_key_field])#[init_osm.index.get_level_values(1) == 140266\t]\n",
    "\n",
    "    result_tail = result[~result.index.isin(result_head.index)].copy()\n",
    "    result_tail[\"reject_reason\"] = \"tail\" \n",
    "    \n",
    "    return result_head, rejected.append(result_tail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.669315Z",
     "start_time": "2020-05-04T07:48:35.647266Z"
    }
   },
   "outputs": [],
   "source": [
    "def retry_with_low_place_rank(osm_results, sent_addresses, \n",
    "                              street_field, housenbr_field,  postcode_field, city_field, country_field,\n",
    "                              check_results=True, osm_structured=False):\n",
    "    vlog(\"Trying to improve place_rank with place_rank < 30 by cleansed house number \")\n",
    "    sent_addresses_26 = osm_results[osm_results.place_rank < 30].merge(sent_addresses)#[osm_addresses.place_rank == 26]\n",
    "    \n",
    "    vlog(f\"    - <30: {sent_addresses_26.shape[0]}\")\n",
    "    sent_addresses_26 = sent_addresses_26[~sent_addresses_26[housenbr_field].fillna(\"\").astype(str).str.match(\"^[0-9]*$\")]\n",
    "    vlog(f\"    - numbers: {sent_addresses_26.shape[0]}\")\n",
    "    sent_addresses_26[\"housenbr_clean\"] = sent_addresses_26[housenbr_field].fillna(\"\").astype(str).str.extract(\"^([0-9]+)\")[0]\n",
    "\n",
    "    sent_addresses_26[\"osm_addr_in\"] =   sent_addresses_26[street_field  ].fillna(\"\") + \", \"+ sent_addresses_26[\"housenbr_clean\"].fillna(\"\") +\", \" + \\\n",
    "                                         sent_addresses_26[postcode_field].fillna(\"\") + \" \" +sent_addresses_26[city_field    ].fillna(\"\") +\", \"+ \\\n",
    "                                         sent_addresses_26[country_field].fillna(\"\")\n",
    "\n",
    "    vlog(\" ; \".join([f\"rank {r}: {c}\" for r, c in sent_addresses_26.place_rank.value_counts().iteritems()]))\n",
    "    #print(osm_results_26.place_rank.value_counts())\n",
    "    osm_results_26, rejected_26 = process_osm(sent_addresses_26, \n",
    "                                              osm_addr_field=\"osm_addr_in\", addr_key_field=addr_key_field, \n",
    "                                              street_field=street_field,housenbr_field=\"housenbr_clean\",  \n",
    "                                              postcode_field=postcode_field, city_field=city_field,\n",
    "                                              country_field=country_field,\n",
    "                                              check_results=check_results,\n",
    "                                              osm_structured=osm_structured)\n",
    "    \n",
    "    if osm_results_26.shape[0]>0:\n",
    "        vlog(\"     - New results with place_rank == 30 after cleansing ({}):\".format(\" ; \".join([f\"rank {r}: {c}\" for r, c in osm_results_26.place_rank.value_counts().iteritems()])))\n",
    "        \n",
    "        osm_results_26 = osm_results_26[osm_results_26.place_rank == 30]\n",
    "        osm_results_26[\"retry_on_26\"] = True\n",
    "        \n",
    "#         display(osm_results_26)\n",
    "        \n",
    "        osm_results = osm_results[~osm_results[addr_key_field].isin(osm_results_26[addr_key_field])].append(osm_results_26, sort=False)\n",
    "        \n",
    "    return osm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.688692Z",
     "start_time": "2020-05-04T07:48:35.674851Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_house_number(street, house_number):\n",
    "    if house_number != \"\" and not pd.isnull(house_number):\n",
    "        return house_number\n",
    "\n",
    "    lpost = parse_address(street)\n",
    "    lpost = {x: y for (y, x) in lpost}\n",
    "    return lpost[\"house_number\"] if \"house_number\" in lpost else np.NaN\n",
    "\n",
    "def add_extra_house_number(osm_addresses, addresses, street_field, housenbr_field):\n",
    "    if \"addr_out_number\" not in osm_addresses:\n",
    "        return osm_addresses\n",
    "        \n",
    "    result = osm_addresses.merge(addresses)\n",
    "    result[\"extra_house_nbr\"] = result.apply(lambda row: find_house_number(row[street_field], row[housenbr_field]), axis=1)\n",
    "\n",
    "    return result[np.concatenate([osm_addresses.keys(), [\"extra_house_nbr\"]])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.732189Z",
     "start_time": "2020-05-04T07:48:35.696069Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_and_process(to_process_addresses, transformers, addr_key_field, street_field, housenbr_field, \n",
    "                          city_field, postcode_field, country_field, check_results=True, osm_structured=False):\n",
    "\n",
    "    t = datetime.now()\n",
    "    method = \"+\".join(transformers)\n",
    "    \n",
    "    # second test : to get rid of \"phantom dask partition\"\n",
    "    if to_process_addresses.shape[0]==0 or to_process_addresses[addr_key_field].duplicated().sum() > 0:\n",
    "        \n",
    "        vlog(\"No more addresses!\")\n",
    "        step_stats = {\"method\": method, \"todo\":  0, \"sent\": 0, \"match\": 0, \"match_26\": 0, \n",
    "                      \"reject_rec\" :0, \"reject_addr\": 0, \"reject_mism\": 0}\n",
    "        return pd.DataFrame(columns=[addr_key_field]), pd.DataFrame(columns=[addr_key_field, \"reject_reason\"]), step_stats\n",
    "\n",
    "    \n",
    "    transformed_addresses = apply_transformers(to_process_addresses, transformers, addr_key_field, \n",
    "                                               street_field=street_field, housenbr_field=housenbr_field, \n",
    "                                               postcode_field=postcode_field, city_field=city_field, country_field=country_field,\n",
    "                                               check_results=check_results)\n",
    "    \n",
    "\n",
    "    if transformed_addresses.shape[0]==0:\n",
    "        vlog(\"No more addresses for this transformers sequence!\")\n",
    "        step_stats = {\"method\": method, \"todo\":  0, \"sent\": 0, \"match\": 0, \"match_26\": 0, \"reject_rec\" :0, \"reject_addr\": 0, \"reject_mism\": 0}\n",
    "        return pd.DataFrame(columns=[addr_key_field]), pd.DataFrame(columns=[addr_key_field, \"reject_reason\"]), step_stats\n",
    "\n",
    "    transformed_addresses[\"osm_addr_in\"] =   transformed_addresses[street_field  ].fillna(\"\") + \", \"+ \\\n",
    "                                             transformed_addresses[housenbr_field].fillna(\"\") + \", \"+ \\\n",
    "                                             transformed_addresses[postcode_field].fillna(\"\") + \" \" +\\\n",
    "                                             transformed_addresses[city_field    ].fillna(\"\") + \", \"+\\\n",
    "                                             transformed_addresses[country_field    ].fillna(\"\") \n",
    "    \n",
    "    \n",
    "    transformed_addresses[\"osm_addr_in\"]= transformed_addresses[\"osm_addr_in\"].str.replace(\"^[ ,]+\", \"\")\n",
    "\n",
    "    if check_with_transformed :\n",
    "        sent_addresses = transformed_addresses\n",
    "    else:\n",
    "        sent_addresses = transformed_addresses[[\"osm_addr_in\", addr_key_field]].merge(to_process_addresses, on=addr_key_field)\n",
    "    \n",
    "    vlog(f\"Will process {sent_addresses.shape[0]} addresses for : transformers = {'+'.join(transformers)}\")\n",
    "\n",
    "    vlog(sent_addresses.head())\n",
    "    vlog(sent_addresses.shape)\n",
    "\n",
    "    timestats[\"transformer\"] += datetime.now() - t\n",
    "         \n",
    "    osm_results, rejected = process_osm(sent_addresses, \n",
    "                                        osm_addr_field=\"osm_addr_in\", addr_key_field=addr_key_field, \n",
    "                                        street_field=street_field, housenbr_field=housenbr_field, \n",
    "                                        postcode_field=postcode_field, city_field=city_field,\n",
    "                                        country_field=country_field,\n",
    "                                        check_results=check_results,\n",
    "                                        osm_structured=osm_structured)\n",
    "    \n",
    "    if with_cleansed_number_on_26 and osm_results.shape[0]>0 : \n",
    "\n",
    "        osm_results = retry_with_low_place_rank(osm_results, sent_addresses, \n",
    "                                                street_field=street_field,housenbr_field=housenbr_field,  \n",
    "                                                postcode_field=postcode_field, city_field=city_field,\n",
    "                                                country_field=country_field,\n",
    "                                                check_results=check_results)\n",
    "\n",
    "    osm_results[\"method\"] = method\n",
    "    rejected[\"method\"] = method\n",
    "\n",
    "    step_stats = {\"method\": method, \n",
    "      \"todo\":        to_process_addresses.shape[0], \n",
    "      \"sent\":        sent_addresses.shape[0], \n",
    "      \"match\":       osm_results.shape[0],\n",
    "      \"match_26\":    osm_results[\"retry_on_26\"].sum() if \"retry_on_26\" in osm_results else 0,\n",
    "      \"reject_rec\" : rejected.shape[0],\n",
    "      \"reject_addr\": rejected[addr_key_field].nunique(),\n",
    "      \"reject_mism\": rejected[rejected.reject_reason == \"mismatch\"][addr_key_field].nunique(),\n",
    "     }\n",
    "    \n",
    "    return osm_results, rejected, step_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:40:49.699726Z",
     "start_time": "2019-09-02T12:40:49.695985Z"
    }
   },
   "source": [
    "## OSM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.749706Z",
     "start_time": "2020-05-04T07:48:35.736906Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_osm(addr, accept_language = \"\"): #lg = \"en,fr,nl\"\n",
    "    params = urllib.parse.urlencode({\"q\": addr,\n",
    "                                    \"format\":\"jsonv2\",\n",
    "                                    \"accept-language\":accept_language,\n",
    "                                    \"addressdetails\":\"1\",\n",
    "                                    \"namedetails\" : \"1\",\n",
    "                                    \"limit\": \"50\"\n",
    "                                    })\n",
    "    \n",
    "    url = \"http://%s/search.php?%s\"%(osm_host, params)\n",
    "    vlog(f\"Call to OSM: {url}\")\n",
    "    try: \n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            res = response.read()\n",
    "            res = json.loads(res)\n",
    "#             return res\n",
    "            return [ {field: item[field] for field in [\"place_id\", \"lat\", \"lon\", \"display_name\", \"address\", \"namedetails\", \"place_rank\", \"category\", \"type\"]} for item in res] \n",
    "    except Exception as e:\n",
    "        raise Exception (f\"Cannot get OSM results ({osm_host}): {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T15:23:43.206219Z",
     "start_time": "2021-07-27T15:23:43.192322Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_osm_struct(street, housenumber, postcode, city, country, accept_language = \"\"): #lg = \"en,fr,nl\"\n",
    "    params = urllib.parse.urlencode({\"street\": f\"{street}, {housenumber}\" if pd.notnull(street) and len(str(street).strip())>0 else \"\" ,\n",
    "                                     \"city\":city,\n",
    "                                     \"postalcode\": postcode,\n",
    "                                     \"country\": country,\n",
    "                                    \"format\":\"jsonv2\",\n",
    "                                    \"accept-language\":accept_language,\n",
    "                                    \"addressdetails\":\"1\",\n",
    "                                    \"namedetails\" : \"1\",\n",
    "                                    \"limit\": \"50\"\n",
    "                                    })\n",
    "    \n",
    "    url = \"http://%s/search.php?%s\"%(osm_host, params)\n",
    "    vlog(f\"Call to OSM: {url}\")\n",
    "    try: \n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            res = response.read()\n",
    "            res = json.loads(res)\n",
    "#             return res\n",
    "            return [ {field: item[field] for field in [\"place_id\", \"lat\", \"lon\", \"display_name\", \"address\", \"namedetails\", \"place_rank\", \"category\", \"type\"]} for item in res] \n",
    "    except Exception as e:\n",
    "        raise Exception (f\"Cannot get OSM results ({osm_host}): {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T12:02:34.392072Z",
     "start_time": "2021-05-17T12:02:34.385904Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# osm_host=\"10.1.0.45:8081\"\n",
    "# get_osm_struct(city=\"Auderghem\", street=None, housenumber=None, postcode=\"1160\", country=\"Belgique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-17T12:02:35.237871Z",
     "start_time": "2021-05-17T12:02:35.229136Z"
    }
   },
   "outputs": [],
   "source": [
    "# osm_host=\"10.0.2.15:7070\"\n",
    "# get_osm_struct(\"avenue fonsny\", \"20\", \"1060\", \"bruxelles\", \"Belgique\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.772528Z",
     "start_time": "2020-05-04T07:48:35.761457Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_osm_details(place_id): #lg = \"en,fr,nl\"\n",
    "    params = urllib.parse.urlencode({\"place_id\": place_id,\n",
    "                                    \"format\":\"json\",\n",
    "                                    })\n",
    "\n",
    "    url = \"http://%s/details.php?%s\"%(osm_host, params)\n",
    "    try: \n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            res = response.read()\n",
    "            return json.loads(res)\n",
    "    except Exception as e: \n",
    "        logger.warning(f\"Problems with get_details for place_id {place_id} (url: {url})\")\n",
    "        print(e)\n",
    "        return {\"category\":\"error\", \"names\": []}\n",
    "#         raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:59:40.764393Z",
     "start_time": "2021-05-12T13:59:40.697724Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eb1a22903ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m def process_osm(df, osm_addr_field, addr_key_field, street_field, housenbr_field, \n\u001b[0;32m----> 2\u001b[0;31m                 \u001b[0mpostcode_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcity_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarity_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                check_osm_results=True) :\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarity_threshold' is not defined"
     ]
    }
   ],
   "source": [
    "def process_osm(df, osm_addr_field, addr_key_field, street_field, housenbr_field, \n",
    "                postcode_field, city_field, country_field, accept_language=\"\", similarity_threshold=similarity_threshold, \n",
    "               check_results=True, osm_structured=False) :\n",
    "    \n",
    "    t = datetime.now()\n",
    "    \n",
    "    if df.shape[0] == 0:\n",
    "        \n",
    "        return pd.DataFrame(columns=[osm_addr_field, addr_key_field]), pd.DataFrame(columns=[osm_addr_field, addr_key_field, \"reject_reason\"])\n",
    "    \n",
    "    if osm_structured:\n",
    "        to_process = df[[osm_addr_field, addr_key_field, street_field, housenbr_field, \n",
    "                postcode_field, city_field, country_field]].drop_duplicates()\n",
    "    else:\n",
    "        to_process = df[[osm_addr_field]].drop_duplicates()\n",
    "    \n",
    "    vlog(f\"OSM: Will process {df.shape[0]} with {to_process.shape[0]} unique values\")\n",
    "    \n",
    "    vlog(\"Most frequent addresses:\")\n",
    "    vlog(df[osm_addr_field].value_counts().head(5))\n",
    "    \n",
    "    \n",
    "    osm_res_field = \"osm_res\"\n",
    "    \n",
    "    \n",
    "    to_process[\"accept_language\"] = accept_language\n",
    "     \n",
    "#     if with_dask : \n",
    "#         dd_to_process = dd.from_pandas(to_process, chunksize=1000 ) #, npartitions=10)\n",
    "\n",
    "#         dask_task = dd_to_process[[osm_addr_field, \"accept_language\"]].apply(lambda row: get_osm(row[osm_addr_field], row[\"accept_language\"]), meta=('x', 'str'), axis=1)\n",
    "\n",
    "#         to_process[osm_res_field] = dask_task.compute() #dchunk.loc[:].apply(map_partitions(lambda r: get_osm(r[addr_field])).compute()#get=get)\n",
    "#     else: \n",
    "    if osm_structured:\n",
    "        to_process[osm_res_field] = to_process.apply(lambda row: \n",
    "                                                   get_osm_struct(street =    row[street_field],\n",
    "                                                                  housenumber=row[housenbr_field],\n",
    "                                                                  postcode=   row[postcode_field],\n",
    "                                                                  city=       row[city_field],\n",
    "                                                                  country=    row[country_field], \n",
    "                                                                  accept_language = row[\"accept_language\"]), axis=1)\n",
    "    else: \n",
    "        to_process[osm_res_field] = to_process[[osm_addr_field, \"accept_language\"]].apply(lambda row: get_osm(row[osm_addr_field], row[\"accept_language\"]), axis=1)\n",
    "        \n",
    "    timestats[\"osm\"] += datetime.now() - t\n",
    "    \n",
    "    t = datetime.now()\n",
    "#     to_process.to_pickle(\"osm_raw.pkl\")\n",
    "    \n",
    "#     to_process = pd.read_pickle(\"osm_raw.pkl\")\n",
    "\n",
    "    vlog(\"     - Parse & split osm results ...\")\n",
    "\n",
    "    osm_results = osm_parse_and_split(to_process, osm_res_field, osm_addr_field=osm_addr_field)\n",
    "    \n",
    "    to_process = None # Allows Garbage collector to free memory ...\n",
    "\n",
    "    osm_results = df[[osm_addr_field, addr_key_field]].merge(osm_results)\n",
    "    \n",
    "    vlog(f\"     - OSM got {osm_results.shape[0]} results for {osm_results[addr_key_field].nunique()} addresses\")\n",
    "    \n",
    "    timestats[\"osm_post\"] += datetime.now() - t\n",
    "#     display(osm_results)\n",
    "    \n",
    "#     osm_results.to_pickle(\"osm_parsed.pkl\")\n",
    "    \n",
    "#     display(osm_results)\n",
    "    if osm_results.shape[0] == 0:\n",
    "        \n",
    "        return osm_results, pd.DataFrame(columns=[osm_addr_field, addr_key_field, \"reject_reason\"])\n",
    "\n",
    "    if check_results:\n",
    "        \n",
    "        t = datetime.now()\n",
    "    \n",
    "        vlog(\"     - Keep relevant results\")\n",
    "        osm_results, osm_reject = osm_keep_relevant_results(osm_results, df, street_field, housenbr_field, \n",
    "                                                            postcode_field, city_field, country_field, \n",
    "                                                            similarity_threshold=similarity_threshold, addr_key_field=addr_key_field)\n",
    "\n",
    "\n",
    "        vlog(f\"     - Got {osm_results.shape[0]} results\")\n",
    "\n",
    "        if use_osm_parent: \n",
    "            vlog(\"     - Trying alternative (parent) names for rejected answers\")\n",
    "\n",
    "            # Keep rejected records that do not correspond to an accepted address\n",
    "            final_rejected = osm_reject[(osm_reject.reject_reason == \"mismatch\") & \n",
    "                                        (~osm_reject[addr_key_field].isin(osm_results[addr_key_field]))]\n",
    "\n",
    "            # Get parent place id from place id calling get_osm_details\n",
    "            parent_place_id = final_rejected.place_id.apply(get_osm_details).apply(lambda x: (x[\"parent_place_id\"] if \"parent_place_id\" in x else 0 ))\n",
    "            \n",
    "            if (parent_place_id == 0).any():\n",
    "                log(\"Got some parent_place_id == 0\")\n",
    "                log(final_rejected[parent_place_id == 0])\n",
    "                parent_place_id = parent_place_id[parent_place_id != 0]\n",
    "\n",
    "            # Get alt names from details of parent\n",
    "            alt_names =  parent_place_id.apply(get_osm_details).apply(lambda x: (x[\"names\"], x[\"category\"])).apply(pd.Series)\n",
    "\n",
    "            # Keep only street parents, and split columns (\"name\", \"name:\"fr\", \"old_name\" ...) in rows\n",
    "\n",
    "            if alt_names.shape[0] >0 and alt_names[alt_names[1] == \"highway\"].shape[0] >0 :\n",
    "                alt_names = alt_names[alt_names[1] == \"highway\"]\n",
    "                alt_names = alt_names[0].apply(pd.Series).stack().reset_index(1).rename(columns= {0: \"alt_names\"})\n",
    "                alt_names = final_rejected.merge(alt_names, left_index=True, right_index=True)\n",
    "\n",
    "                # Keep only alt names that are different from street name\n",
    "                alt_names = alt_names[alt_names.addr_out_street != alt_names.alt_names]\n",
    "\n",
    "                # Remove \"old\" similarity values\n",
    "                alt_names = alt_names.drop([f for f in alt_names if \"SIM\" in f], axis=1)\n",
    "\n",
    "                keep, reject  = ignore_mismatch_keep_bests(alt_names, addr_key_field, \n",
    "                                              street_fields_a = [\"alt_names\"],   housenbr_field_a = \"addr_out_number\", postcode_field_a = \"addr_out_postcode\", city_field_a = \"addr_out_city\",\n",
    "                                              street_field_b = street_field,  housenbr_field_b = housenbr_field,    postcode_field_b = postcode_field,      city_field_b = city_field,)\n",
    "\n",
    "\n",
    "                osm_results = osm_results.append(keep, sort=False)\n",
    "            #     print(osm_reject.shape)\n",
    "                osm_reject = osm_reject[~ osm_reject[[addr_key_field,\"place_id\"]].astype(str).apply(\";\".join, axis=1).isin(keep[[addr_key_field, \"place_id\"]].astype(str).apply(\";\".join, axis=1)) ] \n",
    "            #     print(osm_reject.shape)\n",
    "                vlog(\"     - Saved : \")\n",
    "                vlog(keep)\n",
    "            else:\n",
    "                vlog(\"     - Not any alt name\")\n",
    "        \n",
    "        timestats[\"checker\"] += datetime.now() - t\n",
    "    else: \n",
    "        \n",
    "        vlog(\"    - Do not check OSM results, just keep the first result for each request.\")\n",
    "        result_head = osm_results.groupby([addr_key_field]).head(1).copy()\n",
    "        result_head[\"SIM_street_which\"] = np.NaN\n",
    "        \n",
    "        osm_reject = osm_results[~osm_results.index.isin(result_head.index)].copy()\n",
    "        osm_reject[\"SIM_street\"]= np.NaN\n",
    "        osm_reject[\"SIM_zip\"]= np.NaN\n",
    "        osm_reject[\"reject_reason\"] = \"tail\"\n",
    "        osm_results = result_head\n",
    "      \n",
    "        \n",
    "    vlog(\"     - Done!\")\n",
    "    \n",
    "    res_columns = [osm_addr_field, addr_key_field, \"place_id\", \"lat\", \"lon\", \"display_name\", \"namedetails\", \"place_rank\", \"category\", \"type\", \"SIM_street_which\", \"SIM_street\", \"SIM_city\", \"SIM_zip\", \"SIM_house_nbr\"] + list(collapse_params.keys()) + [\"addr_out_other\"] \n",
    "    res_columns = [c for c in res_columns if c in osm_results ]\n",
    "    return osm_results[res_columns], osm_reject\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.873154Z",
     "start_time": "2020-05-04T07:48:35.847010Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def osm_parse_and_split(df, osm_res_field, osm_addr_field, prefix=\"addr_\", drop_osm=True):\n",
    "    osm_result_item_field = \"osm_item_result\"\n",
    "\n",
    "    df = df.set_index([osm_addr_field])\n",
    "    \n",
    "    vlog(\"        * Unstacking...\")\n",
    "    df_split = df[osm_res_field].apply(pd.Series)\n",
    "    \n",
    "    if df_split.shape[1] == 0: # None of the addresses were matched by Nominatim\n",
    "        return pd.DataFrame(columns = [osm_addr_field])\n",
    "    \n",
    "    osm_results = pd.DataFrame(df_split.stack()).rename(columns = {0:osm_result_item_field})\n",
    "    \n",
    "    vlog(\"        * Extract items\")\n",
    "\n",
    "    for item in osm_results.iloc[0][osm_result_item_field].keys() :\n",
    "        osm_results[item] = osm_results[osm_result_item_field].apply(lambda x: x[item] if item in x else None)\n",
    "    \n",
    "    \n",
    "    addr_items = []\n",
    "\n",
    "    for row in osm_results[osm_result_item_field].apply(lambda x: x[\"address\"]):\n",
    "        for addr_item in row.keys():\n",
    "            addr_items.append(addr_item)\n",
    "            \n",
    "    addr_items = pd.Series(addr_items).value_counts().keys().values\n",
    "    \n",
    "    for addr_item in addr_items:\n",
    "        osm_results[prefix+addr_item] = osm_results[osm_result_item_field].apply(lambda x: x[\"address\"][addr_item] if addr_item in x[\"address\"] else None)\n",
    "        \n",
    "    # Keep only \"namedetails\" if category == \"highway\"\n",
    "    osm_results[\"namedetails\"] = np.where(osm_results[\"category\"] == \"highway\", osm_results[\"namedetails\"].apply(lambda dct: \" - \".join(dct.values())), \"\")\n",
    "    \n",
    "    osm_results = osm_results.drop(columns=[\"address\"] + ([osm_result_item_field] if drop_osm else []))\n",
    "    \n",
    "    osm_results.place_rank=osm_results.place_rank.astype(int)\n",
    "    \n",
    "    osm_results = add_addr_out_columns(osm_results, prefix)\n",
    "    \n",
    "    osm_results = osm_results.reset_index().rename(columns={\"level_1\": \"osm_order\"})\n",
    "    \n",
    "    return osm_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.893057Z",
     "start_time": "2020-05-04T07:48:35.878186Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def osm_keep_relevant_results(osm_results, addresses, street_field,  housenbr_field, postcode_field, city_field, country_field, similarity_threshold,\n",
    "                              addr_key_field, max_res=1):\n",
    "    \n",
    "    osm_results_street = osm_results.reset_index().merge(addresses[[addr_key_field, street_field, postcode_field, housenbr_field, city_field, country_field]], left_on=addr_key_field, right_on=addr_key_field, how=\"left\").set_index(osm_results.index)\n",
    "    \n",
    "    assert osm_results_street.shape[0] == osm_results.shape[0]\n",
    "\n",
    "    keep, reject  = ignore_mismatch_keep_bests(osm_results_street, addr_key_field, \n",
    "                                      street_fields_a = [\"addr_out_street\", \"addr_out_other\", \"namedetails\"], housenbr_field_a = \"addr_out_number\", postcode_field_a = \"addr_out_postcode\", city_field_a = \"addr_out_city\", \n",
    "                                      street_field_b = street_field,      housenbr_field_b = housenbr_field,    postcode_field_b = postcode_field,      city_field_b = city_field,\n",
    "                                      secondary_sort_field = \"osm_order\", \n",
    "                                      max_res=max_res)\n",
    "    \n",
    "    return keep, reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.919455Z",
     "start_time": "2020-05-04T07:48:35.899846Z"
    }
   },
   "outputs": [],
   "source": [
    "def collapse(df, columns, prefix=None, method=\"fillna\"):\n",
    "    \n",
    "    if prefix: \n",
    "        columns = [prefix+col for col in columns]\n",
    "        \n",
    "    if method==\"fillna\":\n",
    "        \n",
    "        res = pd.Series(index = df.index)#[columns[0]]\n",
    "\n",
    "        for col in columns:\n",
    "            if col in df.keys():\n",
    "                res = res.fillna(df[col])\n",
    "    elif method== \"set\":\n",
    "        res = df[columns].apply(lambda lst: set([x for x in lst if not pd.isnull(x)]), axis=1).apply(\" - \".join)\n",
    "    \n",
    "    else :\n",
    "        raise Exception(\"Wrong method ! \" + method)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.939349Z",
     "start_time": "2020-05-04T07:48:35.926310Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_addr_out_columns(osm_results, prefix):\n",
    "    \n",
    "    other_columns = osm_results.keys()\n",
    "\n",
    "    for out_column in collapse_params:\n",
    "        other_columns = [col for col in other_columns if col.replace(prefix, \"\") not in collapse_params[out_column] and col.startswith(prefix)]\n",
    "    other_columns.remove('addr_country_code')\n",
    "    \n",
    "    if \"addr_state\" in other_columns:\n",
    "        other_columns.remove('addr_state')\n",
    "    \n",
    "    for out_column in collapse_params:\n",
    "        osm_results[out_column] = collapse(osm_results, collapse_params[out_column], \"addr_\", \"fillna\")\n",
    "        \n",
    "    osm_results[\"addr_out_other\"] = collapse(osm_results, other_columns, \"\", \"set\") if len(other_columns)>0 else np.NaN\n",
    "    \n",
    "    return osm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T10:40:47.471046Z",
     "start_time": "2019-11-08T10:40:47.457752Z"
    }
   },
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.973978Z",
     "start_time": "2020-05-04T07:48:35.945710Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_transformers(addresses, transformers, addr_key_field, street_field, housenbr_field, postcode_field, \n",
    "                       city_field, country_field, check_results):\n",
    "    \n",
    "    if transformers == [\"orig\"]:\n",
    "        return addresses.copy()\n",
    "    \n",
    "    init_addresses = addresses.copy()\n",
    "    transformed_addresses = addresses.copy()\n",
    "    \n",
    "    for transformer in transformers: \n",
    "        # TODO : cache system to avoid recompuing libpostal/photon when already done.\n",
    "        vlog(f\"   transformer: {transformer}\")\n",
    "        \n",
    "        if transformer == \"orig\": \n",
    "            pass # Don't do anything, keep original values\n",
    "        \n",
    "        elif re.match(r\"regex\\[[a-z]+\\]\", transformer):\n",
    "            gr = re.match(r\"regex\\[([a-z]+)\\]\", transformer)\n",
    "            regex_key = gr.groups(0)[0]\n",
    "            \n",
    "            transformed_addresses =  regex_transformer(transformed_addresses, addr_key_field, street_field, housenbr_field, postcode_field, city_field, country_field)\n",
    "            \n",
    "        elif transformer == \"nonum\":\n",
    "            #transformed_addresses = transformed_addresses[transformed_addresses[housenbr_field].fillna(\"\").str.len()>0].copy()\n",
    "            transformed_addresses[housenbr_field] = \"\"\n",
    "\n",
    "        elif transformer == \"nostreet\":\n",
    "            #transformed_addresses = transformed_addresses[transformed_addresses[housenbr_field].fillna(\"\").str.len()>0].copy()\n",
    "            transformed_addresses[housenbr_field] = \"\"\n",
    "            transformed_addresses[street_field] = \"\"\n",
    "\n",
    "        elif transformer == \"libpostal\": \n",
    "            transformed_addresses = libpostal_transformer(transformed_addresses, addr_key_field, street_field, housenbr_field, postcode_field, \n",
    "                                                          city_field, country_field, check_results)\n",
    "#             display(transformed_addresses)\n",
    "            \n",
    "        elif transformer == \"photon\": \n",
    "            transformed_addresses = photon_transformer(transformed_addresses, addr_key_field, street_field, housenbr_field, postcode_field, \n",
    "                                                       city_field, country_field, check_results)\n",
    "        else :\n",
    "            assert False, f\"Wrong transformer type : {transformer}\"\n",
    "\n",
    "        if transformed_addresses.shape[0]==0:\n",
    "            vlog(\"No more addresses after transformers!\")\n",
    "            transformed_addresses[addr_key_field] = np.NaN\n",
    "            break\n",
    "    \n",
    "    # Return only records that have been modified by transfomer sequence\n",
    "    \n",
    "    changed = pd.Series(index=transformed_addresses.index)\n",
    "    changed[:] = False\n",
    "    \n",
    "    fields = [street_field, housenbr_field, city_field, postcode_field, country_field]\n",
    "\n",
    "    init_addresses = transformed_addresses[[addr_key_field]].merge(init_addresses).set_index(transformed_addresses.index)\n",
    "\n",
    "    \n",
    "    for field in fields:\n",
    "        if field in transformed_addresses:\n",
    "            changed = changed | (init_addresses[field].fillna(\"\").astype(str).str.lower() != transformed_addresses[field].fillna(\"\").astype(str).str.lower())\n",
    "\n",
    "    \n",
    "    return transformed_addresses[changed].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:16:06.893035Z",
     "start_time": "2019-09-02T12:16:06.884632Z"
    }
   },
   "source": [
    "## Photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:35.986417Z",
     "start_time": "2020-05-04T07:48:35.979355Z"
    }
   },
   "outputs": [],
   "source": [
    "photon_street_field   = \"photon_street\"\n",
    "photon_name_field     = \"photon_name\" # Sometimes, streetname is put in \"name\" field (especially for request without house number)\n",
    "photon_postcode_field = \"photon_postcode\"\n",
    "photon_city_field     = \"photon_city\"\n",
    "photon_country_field  = \"photon_country\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.002248Z",
     "start_time": "2020-05-04T07:48:35.991821Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_photon(addr):\n",
    "    params = urllib.parse.urlencode({\"q\": addr})\n",
    "    url = \"http://%s/api?%s\"%(photon_host, params)\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            res = response.read()\n",
    "            return json.loads(res)\n",
    "    except Exception as e:\n",
    "         raise Exception (f\"Cannot connect to Photon ({photon_host}):  {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.028586Z",
     "start_time": "2020-05-04T07:48:36.007990Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def photon_keep_relevant_results(photon_results, addresses, \n",
    "                                 addr_street_field, addr_housenbr_field, addr_postcode_field, addr_city_field, addr_country_field,\n",
    "                                 addr_key_field, similarity_threshold):\n",
    "    \n",
    "    photon_ext = photon_results.merge(addresses[[addr_key_field,  addr_street_field, addr_housenbr_field, addr_postcode_field, \n",
    "                                                 addr_city_field, addr_country_field]])\n",
    "    \n",
    "    if photon_ext.shape[0] == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    photon_ext[\"fake_house_number\"] = \"\"\n",
    "    \n",
    "#     display(photon_ext)\n",
    "    keep, reject  = ignore_mismatch_keep_bests(photon_ext, addr_key_field, \n",
    "                                  street_fields_a = [photon_street_field], housenbr_field_a = \"fake_house_number\", postcode_field_a = photon_postcode_field, city_field_a = photon_city_field, \n",
    "                                  street_field_b =   addr_street_field, housenbr_field_b = \"fake_house_number\", postcode_field_b =   addr_postcode_field, city_field_b =  addr_city_field,\n",
    "                                     secondary_sort_field = \"photon_order\")\n",
    "    \n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.090093Z",
     "start_time": "2020-05-04T07:48:36.037509Z"
    }
   },
   "outputs": [],
   "source": [
    "def photon_parse_and_split(res, addr_field, photon_col):\n",
    "    res[\"photon_parsed\"] = res[photon_col].apply(lambda j:j[\"features\"] if \"features\" in j else None)\n",
    "    \n",
    "    res = res.set_index([addr_field])\n",
    "    \n",
    "    s = res.photon_parsed.apply(pd.Series)\n",
    "#     print(s.shape)\n",
    "    if s.shape[0] == 0 or s.shape[1] == 0:\n",
    "        return pd.DataFrame(columns = [addr_field])\n",
    "    \n",
    "    photon_results = pd.DataFrame(s.stack()).rename(columns = {0:photon_col})\n",
    "    \n",
    "    for item in photon_results[photon_col].apply(lambda x: x.keys())[0]:\n",
    "        photon_results[item] = photon_results[photon_col].apply(lambda x: x[item] if item in x else None)\n",
    "   \n",
    "    addr_items = []\n",
    "\n",
    "    for row in photon_results[photon_col].apply(lambda x: x[\"properties\"]):\n",
    "        for addr_item in row.keys():\n",
    "            addr_items.append(addr_item)\n",
    "\n",
    "    addr_items = pd.Series(addr_items).value_counts().iloc[0:30].keys().values\n",
    "\n",
    "    prefix=\"photon_\"\n",
    "    for addr_item in addr_items:\n",
    "        #print(addr_item)\n",
    "        photon_results[prefix+addr_item] = photon_results[photon_col].apply(lambda x: x[\"properties\"][addr_item] if addr_item in x[\"properties\"] else None)\n",
    "    \n",
    "    for f in [photon_street_field, photon_postcode_field, photon_city_field, photon_country_field]:\n",
    "        if f not in photon_results:\n",
    "            vlog(f\"Photon: adding field {f}\")\n",
    "            photon_results[f] = \"\"\n",
    "    \n",
    "    if photon_name_field in photon_results:\n",
    "        photon_results[photon_street_field] = photon_results[photon_street_field].fillna(photon_results[photon_name_field])\n",
    "    \n",
    "    photon_results[\"lat\"] = photon_results[\"geometry\"].apply(lambda x: x[\"coordinates\"][0])\n",
    "    photon_results[\"lon\"] = photon_results[\"geometry\"].apply(lambda x: x[\"coordinates\"][1])\n",
    "\n",
    "    photon_results = photon_results.drop([photon_col, \"geometry\", \"photon_extent\", \"type\",\"properties\", \"photon_osm_id\"], axis=1, errors=\"ignore\").reset_index().rename(columns={\"level_1\": \"photon_order\"})#res #parse_and_split(res, osm_field, key=addr_field)\n",
    "    return photon_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.109828Z",
     "start_time": "2020-05-04T07:48:36.096972Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_photon(df, addr_field, photon_col, addr_key_field):\n",
    "    to_process = df[[addr_field]].drop_duplicates()\n",
    "    \n",
    "    vlog(f\"Photon: Will process {df.shape[0]} with {to_process.shape[0]} unique values\")\n",
    "    \n",
    "#     if with_dask : \n",
    "#         dd_to_process = dd.from_pandas(to_process, npartitions=10)\n",
    "\n",
    "#         dask_task = dd_to_process[addr_field].apply(get_photon, meta=('x', 'str'))\n",
    "\n",
    "#         to_process[photon_col] = dask_task.compute()\n",
    "#     else: \n",
    "    to_process[photon_col] = to_process[addr_field].apply(get_photon)\n",
    "        \n",
    "    photon_results = photon_parse_and_split(to_process, addr_field, photon_col)\n",
    "    \n",
    "    vlog(f\"Photon got {photon_results.shape[0]} results for {df.shape[0]} addresses\")\n",
    "    \n",
    "    \n",
    "    photon_results = df[[addr_key_field, addr_field]].merge(photon_results)\n",
    "    \n",
    "    return photon_results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.137206Z",
     "start_time": "2020-05-04T07:48:36.115988Z"
    }
   },
   "outputs": [],
   "source": [
    "def photon_transformer(addresses, addr_key_field, street_field, housenbr_field, postcode_field, city_field, country_field,\n",
    "                       check_results, similarity_threshold=similarity_threshold):\n",
    "    \n",
    "    t = datetime.now() \n",
    "    photon_addr = addresses[[addr_key_field, street_field, housenbr_field, postcode_field, city_field, country_field]].copy()\n",
    "    \n",
    "    photon_addr[\"photon_full_addr\"] = photon_addr[street_field].fillna(\"\") +\", \"+ \\\n",
    "                                photon_addr[postcode_field].fillna(\"\") + \" \" +photon_addr[city_field].fillna(\"\")+\", \"+ \\\n",
    "                                photon_addr[country_field].fillna(\"\") \n",
    "    \n",
    "    # Send to Photon\n",
    "    photon_res = process_photon(photon_addr, \"photon_full_addr\", \"photon\", addr_key_field = addr_key_field)\n",
    "\n",
    "    if check_results:\n",
    "\n",
    "        photon_res_sel = photon_keep_relevant_results(photon_res, photon_addr, addr_street_field=street_field, \n",
    "                                                        addr_housenbr_field = housenbr_field,\n",
    "                                                        addr_postcode_field = postcode_field,  addr_city_field = city_field,\n",
    "                                                        addr_country_field  = country_field,\n",
    "                                                        addr_key_field = addr_key_field,  similarity_threshold=similarity_threshold)\n",
    "    else:\n",
    "         photon_res_sel = photon_res.merge(addresses[[addr_key_field,  street_field, housenbr_field, postcode_field, \n",
    "                                                 city_field, country_field]])\n",
    "            \n",
    "    if photon_res_sel.shape[0] == 0:\n",
    "        return photon_res_sel\n",
    "    \n",
    "    fields = [(street_field, photon_street_field), (housenbr_field, housenbr_field), # We do not consider photon house number\n",
    "              (city_field, photon_city_field), (postcode_field, photon_postcode_field),\n",
    "              (country_field, photon_country_field)]\n",
    "    \n",
    "    fields_out    = [field_in      for field_in, field_photon in fields]\n",
    "    fields_photon = [field_photon  for field_in, field_photon in fields]\n",
    "   \n",
    "    timestats[\"photon\"] += datetime.now() - t\n",
    "    return photon_res_sel[[addr_key_field] + fields_photon].rename(columns= {field_photon: field_in for field_in, field_photon in fields})[[addr_key_field] + fields_out]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libpostal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.153621Z",
     "start_time": "2020-05-04T07:48:36.142737Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if with_rest_libpostal:\n",
    "    import urllib\n",
    "    # Assuming LibpostalREST flask is running\n",
    "    def parse_address(address):\n",
    "        \n",
    "        import requests\n",
    "\n",
    "        url = \"http://%s/parser\"%(libpostal_host)\n",
    "        params = {\"query\": address}\n",
    "\n",
    "        try: \n",
    "            res = requests.post(url, json = params)\n",
    "        except Exception as e:\n",
    "             raise Exception (f\"Cannot connect to Libpostal ({libpostal_host}): {e}\")\n",
    "    \n",
    "        res = json.loads(res.content.decode())\n",
    "\n",
    "        return res\n",
    "    \n",
    "else: \n",
    "    from postal.parser import parse_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.165023Z",
     "start_time": "2020-05-04T07:48:36.158911Z"
    }
   },
   "outputs": [],
   "source": [
    "lpost_street_field   = \"lpost_road\"\n",
    "lpost_housenbr_field = \"lpost_house_number\"\n",
    "lpost_postcode_field = \"lpost_postcode\"\n",
    "lpost_city_field     = \"lpost_city\"\n",
    "lpost_country_field  = \"lpost_country\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.199767Z",
     "start_time": "2020-05-04T07:48:36.170622Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def libpostal_transformer(addresses, addr_key_field, street_field, housenbr_field, postcode_field, city_field, country_field,\n",
    "                          check_results, similarity_threshold = similarity_threshold):\n",
    "    \n",
    "    t = datetime.now() \n",
    "    \n",
    "    libpost_addr = addresses[[addr_key_field, street_field, housenbr_field, postcode_field, city_field, country_field]].copy()\n",
    "\n",
    "    # Make full address for libpostal\n",
    "    \n",
    "    libpost_addr[\"lpost_full_addr_in\"] = libpost_addr[street_field] + \" \"+ libpost_addr[housenbr_field].fillna(\"\")+\", \"+\\\n",
    "                    libpost_addr[postcode_field].fillna(\"\") + \" \" +libpost_addr[city_field].fillna(\"\") +\",  \" +\\\n",
    "                    libpost_addr[country_field].fillna(\"\")\n",
    "    \n",
    "    # Apply libpostal\n",
    "    \n",
    "    libpost_addr[\"lpost\"] = libpost_addr.lpost_full_addr_in.apply(parse_address)\n",
    "    libpost_addr[\"lpost\"] = libpost_addr.lpost.apply(lambda lst: {x: y for (y, x) in lst})\n",
    "    \n",
    "    # Split libpostal results\n",
    "    for field in \"road\", \"house_number\", \"postcode\", \"city\", \"house\", \"country\":\n",
    "        libpost_addr[\"lpost_\"+field] =libpost_addr.lpost.apply(lambda rec: rec[field] if field in rec else np.NAN)\n",
    "            \n",
    "    if check_results:\n",
    "        # Keep only \"close\" results\n",
    "        libpost_addr, reject  = ignore_mismatch_keep_bests(libpost_addr, addr_key_field, \n",
    "                                      street_fields_a = [street_field], housenbr_field_a = housenbr_field, postcode_field_a = postcode_field,       city_field_a = city_field,  \n",
    "                                      street_field_b = lpost_street_field,   housenbr_field_b = lpost_housenbr_field, postcode_field_b = lpost_postcode_field, city_field_b = lpost_city_field, \n",
    "                                                  secondary_sort_field=addr_key_field)\n",
    "        vlog(\"Rejected lipbostal results: \")\n",
    "        vlog(reject)\n",
    "    if libpost_addr.shape[0] == 0:\n",
    "        \n",
    "        return pd.DataFrame(columns=[osm_addr_field, addr_key_field])#,  libpost_addr\n",
    "        \n",
    "    \n",
    "    fields =        [(street_field, lpost_street_field), (housenbr_field, lpost_housenbr_field), \n",
    "                     (city_field, lpost_city_field), (postcode_field, lpost_postcode_field),\n",
    "                     (country_field, lpost_country_field) ]\n",
    "    fields_out    = [field_in      for field_in, field_lpost in fields]\n",
    "    fields_lpost  = [field_lpost   for field_in, field_lpost in fields]\n",
    "   \n",
    "    timestats[\"libpostal\"] += datetime.now() - t\n",
    "    return libpost_addr[[addr_key_field] + fields_lpost].rename(columns= {field_lpost: field_in for field_in, field_lpost in fields})[[addr_key_field] + fields_out]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:48:36.220623Z",
     "start_time": "2020-05-04T07:48:36.204843Z"
    }
   },
   "outputs": [],
   "source": [
    "def regex_transformer(addresses, addr_key_field, street_field, housenbr_field, postcode_field, city_field, \n",
    "                      country_field, regex_key=\"init\"):\n",
    "    \n",
    "    regex_addr = addresses[[addr_key_field, street_field, housenbr_field, postcode_field, city_field, country_field]].copy()\n",
    "\n",
    "    for (field, match, repl) in regex_replacements[regex_key]:\n",
    "        vlog(f\"{field}: {match}\")\n",
    "#         display(regex_addr[field])\n",
    "        new_values = regex_addr[field].fillna(\"\").str.replace(match, repl)\n",
    "        new_values_sel = regex_addr[field].fillna(\"\") != new_values\n",
    "        \n",
    "        if new_values_sel.sum()>0:\n",
    "            vlog(regex_addr[new_values_sel])\n",
    "\n",
    "            regex_addr[field] = new_values\n",
    "            vlog(\"-->\")\n",
    "            #display(libpost_addr[libpost_addr[field].fillna(\"\").str.contains(match)])\n",
    "            vlog(regex_addr[new_values_sel])\n",
    "        else: \n",
    "            vlog(\"None\")\n",
    "\n",
    "    return regex_addr\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "862.4px",
    "left": "22px",
    "top": "110.8px",
    "width": "191.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
